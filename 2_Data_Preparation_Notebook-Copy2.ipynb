{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dublin Bike CA 1\n",
    "\n",
    "## 2 Data Preparation Notebook\n",
    "\n",
    "\n",
    "Ronan Downes | [Github](https://github.com/ronandownes/dublinbikes-CA1) | November 2022 \n",
    "\n",
    "Prerequisite Notebook: **1 Data Loading Notebook**\n",
    "\n",
    "Follow on Notebook: **3 Data Visualisation**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries and files \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "import datetime as dt\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert CSVs to pandas dfs and clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1_df=  pd.read_csv('data/21_1.csv')\n",
    "# q2_df = pd.read_csv('data/21_2.csv')\n",
    "# q3_df=  pd.read_csv('data/21_3.csv')\n",
    "# q4_df = pd.read_csv('data/21_4.csv')\n",
    "df = pd.read_csv('data/bikes.csv')\n",
    "wdf=pd.read_csv('data/weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION ID                   111\n",
       "TIME                      103038\n",
       "LAST UPDATED             5039168\n",
       "NAME                         111\n",
       "BIKE STANDS                   18\n",
       "AVAILABLE BIKE STANDS         41\n",
       "AVAILABLE BIKES               41\n",
       "STATUS                         2\n",
       "ADDRESS                      111\n",
       "LATITUDE                     111\n",
       "LONGITUDE                    111\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique (axis=0, dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df[df['STATUS'] == 'Open']    #Effectively removing data from closed stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION ID                   111\n",
       "TIME                      103038\n",
       "LAST UPDATED             5038920\n",
       "NAME                         111\n",
       "BIKE STANDS                   18\n",
       "AVAILABLE BIKE STANDS         41\n",
       "AVAILABLE BIKES               41\n",
       "STATUS                         1\n",
       "ADDRESS                      111\n",
       "LATITUDE                     111\n",
       "LONGITUDE                    111\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique (axis=0, dropna=True) #check that only one \"STATUS\" remains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column name 'TIME'\n",
    "df=df.drop(['TIME'], axis=1)\n",
    "df=df.drop(['STATUS'], axis=1)   # 774.8+ MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows where no bike has been taken or returned since previous readings\n",
    "df.drop_duplicates(keep= 'first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6222487 entries, 0 to 11283233\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   STATION ID             int64  \n",
      " 1   LAST UPDATED           object \n",
      " 2   NAME                   object \n",
      " 3   BIKE STANDS            int64  \n",
      " 4   AVAILABLE BIKE STANDS  int64  \n",
      " 5   AVAILABLE BIKES        int64  \n",
      " 6   ADDRESS                object \n",
      " 7   LATITUDE               float64\n",
      " 8   LONGITUDE              float64\n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 474.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() #memory usage: 474.7+ MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Filter to dates and removes duplicate rows\n",
    "Usage of the DataFrame.loc[] Method to Filter Data to interval of interest and drop the \"TIME\" feature because it is reduntant.\n",
    "\n",
    "The aim is to plan rebalancing and growth based on ML models so COVID-19 lockdown and xmas Holidays are ommitted.\n",
    "Memory usage is 685 MB after Date filter and before merging weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4188876 entries, 3109999 to 10611332\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   STATION ID             int64  \n",
      " 1   LAST UPDATED           object \n",
      " 2   NAME                   object \n",
      " 3   BIKE STANDS            int64  \n",
      " 4   AVAILABLE BIKE STANDS  int64  \n",
      " 5   AVAILABLE BIKES        int64  \n",
      " 6   ADDRESS                object \n",
      " 7   LATITUDE               float64\n",
      " 8   LONGITUDE              float64\n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 319.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4188876, 9)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = '2021-04-12'    #Lockdown restrictions lifted\n",
    "end_date = '2021-12-11'      # Traditiona date for beginning of xmas holidays \n",
    "after_start_date = df['LAST UPDATED'] >= start_date\n",
    "before_end_date = df['LAST UPDATED'] <= end_date\n",
    "between_two_dates = after_start_date & before_end_date\n",
    "# Using pandas.DataFrame.loc to Filter Rows by Dates\n",
    "df = df.loc[between_two_dates]\n",
    "df.drop_duplicates(keep= 'first',inplace=True)\n",
    "df.info()   #memory usage: 319.6+ MB\n",
    "df.shape # shape is (4188876, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns renamed using a  capitalized snake  style for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove spaces in columns name\n",
    "df.columns = df.columns.str.replace(' ','_')\n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns = df.columns.str.capitalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_id</th>\n",
       "      <th>Last_updated</th>\n",
       "      <th>Name</th>\n",
       "      <th>Bike_stands</th>\n",
       "      <th>Available_bike_stands</th>\n",
       "      <th>Available_bikes</th>\n",
       "      <th>Address</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3109999</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-04-12 00:00:15</td>\n",
       "      <td>BLESSINGTON STREET</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Blessington Street</td>\n",
       "      <td>53.35677</td>\n",
       "      <td>-6.26814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110001</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-04-12 00:10:21</td>\n",
       "      <td>BLESSINGTON STREET</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Blessington Street</td>\n",
       "      <td>53.35677</td>\n",
       "      <td>-6.26814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110003</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-04-12 00:20:28</td>\n",
       "      <td>BLESSINGTON STREET</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Blessington Street</td>\n",
       "      <td>53.35677</td>\n",
       "      <td>-6.26814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110005</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-04-12 00:30:34</td>\n",
       "      <td>BLESSINGTON STREET</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Blessington Street</td>\n",
       "      <td>53.35677</td>\n",
       "      <td>-6.26814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110007</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-04-12 00:40:40</td>\n",
       "      <td>BLESSINGTON STREET</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Blessington Street</td>\n",
       "      <td>53.35677</td>\n",
       "      <td>-6.26814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Station_id         Last_updated                Name  Bike_stands  \\\n",
       "3109999           2  2021-04-12 00:00:15  BLESSINGTON STREET           20   \n",
       "3110001           2  2021-04-12 00:10:21  BLESSINGTON STREET           20   \n",
       "3110003           2  2021-04-12 00:20:28  BLESSINGTON STREET           20   \n",
       "3110005           2  2021-04-12 00:30:34  BLESSINGTON STREET           20   \n",
       "3110007           2  2021-04-12 00:40:40  BLESSINGTON STREET           20   \n",
       "\n",
       "         Available_bike_stands  Available_bikes             Address  Latitude  \\\n",
       "3109999                      8               12  Blessington Street  53.35677   \n",
       "3110001                      8               12  Blessington Street  53.35677   \n",
       "3110003                      8               12  Blessington Street  53.35677   \n",
       "3110005                      8               12  Blessington Street  53.35677   \n",
       "3110007                      8               12  Blessington Street  53.35677   \n",
       "\n",
       "         Longitude  \n",
       "3109999   -6.26814  \n",
       "3110001   -6.26814  \n",
       "3110003   -6.26814  \n",
       "3110005   -6.26814  \n",
       "3110007   -6.26814  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdf.rename(columns = {'last updated':'updated','available bike stands':'free_stands','available bikes':'bikes'}, inplace = True)\n",
    "# sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add individual date and time columns\n",
    "df['Date_time'] = [dt.datetime.strptime(d, \"%Y-%m-%d %H:%M:%S\") for d in df[\"Last_updated\"]]\n",
    "df['Last_updated'] = [dt.datetime.time(d) for d in df['Date_time']] \n",
    "df['Date'] = [dt.datetime.date(d) for d in df['Date_time']] \n",
    "df['Merge_date'] = df['Date_time'].dt.round('H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_id</th>\n",
       "      <th>Last_updated</th>\n",
       "      <th>Name</th>\n",
       "      <th>Bike_stands</th>\n",
       "      <th>Available_bike_stands</th>\n",
       "      <th>Available_bikes</th>\n",
       "      <th>Status</th>\n",
       "      <th>Address</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>date_for_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3109999</th>\n",
       "      <td>2</td>\n",
       "      <td>00:00:15</td>\n",
       "      <td>BLESSINGTON STREET</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Open</td>\n",
       "      <td>Blessington Street</td>\n",
       "      <td>53.35677</td>\n",
       "      <td>-6.26814</td>\n",
       "      <td>2021-04-12 00:00:15</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>2021-04-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110001</th>\n",
       "      <td>2</td>\n",
       "      <td>00:10:21</td>\n",
       "      <td>BLESSINGTON STREET</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Open</td>\n",
       "      <td>Blessington Street</td>\n",
       "      <td>53.35677</td>\n",
       "      <td>-6.26814</td>\n",
       "      <td>2021-04-12 00:10:21</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>2021-04-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110003</th>\n",
       "      <td>2</td>\n",
       "      <td>00:20:28</td>\n",
       "      <td>BLESSINGTON STREET</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Open</td>\n",
       "      <td>Blessington Street</td>\n",
       "      <td>53.35677</td>\n",
       "      <td>-6.26814</td>\n",
       "      <td>2021-04-12 00:20:28</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>2021-04-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110005</th>\n",
       "      <td>2</td>\n",
       "      <td>00:30:34</td>\n",
       "      <td>BLESSINGTON STREET</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Open</td>\n",
       "      <td>Blessington Street</td>\n",
       "      <td>53.35677</td>\n",
       "      <td>-6.26814</td>\n",
       "      <td>2021-04-12 00:30:34</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>2021-04-12 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110007</th>\n",
       "      <td>2</td>\n",
       "      <td>00:40:40</td>\n",
       "      <td>BLESSINGTON STREET</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Open</td>\n",
       "      <td>Blessington Street</td>\n",
       "      <td>53.35677</td>\n",
       "      <td>-6.26814</td>\n",
       "      <td>2021-04-12 00:40:40</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>2021-04-12 01:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Station_id Last_updated                Name  Bike_stands  \\\n",
       "3109999           2     00:00:15  BLESSINGTON STREET           20   \n",
       "3110001           2     00:10:21  BLESSINGTON STREET           20   \n",
       "3110003           2     00:20:28  BLESSINGTON STREET           20   \n",
       "3110005           2     00:30:34  BLESSINGTON STREET           20   \n",
       "3110007           2     00:40:40  BLESSINGTON STREET           20   \n",
       "\n",
       "         Available_bike_stands  Available_bikes Status             Address  \\\n",
       "3109999                      8               12   Open  Blessington Street   \n",
       "3110001                      8               12   Open  Blessington Street   \n",
       "3110003                      8               12   Open  Blessington Street   \n",
       "3110005                      8               12   Open  Blessington Street   \n",
       "3110007                      8               12   Open  Blessington Street   \n",
       "\n",
       "         Latitude  Longitude            DATETIME        DATE  \\\n",
       "3109999  53.35677   -6.26814 2021-04-12 00:00:15  2021-04-12   \n",
       "3110001  53.35677   -6.26814 2021-04-12 00:10:21  2021-04-12   \n",
       "3110003  53.35677   -6.26814 2021-04-12 00:20:28  2021-04-12   \n",
       "3110005  53.35677   -6.26814 2021-04-12 00:30:34  2021-04-12   \n",
       "3110007  53.35677   -6.26814 2021-04-12 00:40:40  2021-04-12   \n",
       "\n",
       "             date_for_merge  \n",
       "3109999 2021-04-12 00:00:00  \n",
       "3110001 2021-04-12 00:00:00  \n",
       "3110003 2021-04-12 00:00:00  \n",
       "3110005 2021-04-12 01:00:00  \n",
       "3110007 2021-04-12 01:00:00  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Weather Data\n",
    "\n",
    "weather = pd.read_csv('hly175.csv')\n",
    "weather['date'] = [dt.datetime.strptime(d, \"%m/%d/%Y %H:%M\") for d in weather['date'] ]\n",
    "weather['date_for_merge'] = weather['date'].dt.round('H')\n",
    "weather = weather[(weather['date'] >= '2019-04-01') & (weather['date'] < '2020-04-02')]\n",
    "weather = weather[['date_for_merge', 'rain', 'temp', 'wetb', 'dewpt', 'vappr', 'rhum', 'msl']]\n",
    "weather['rain'] = weather['rain'].astype(float)\n",
    "weather['temp'] = weather['temp'].astype(float)\n",
    "\n",
    "#add binary variables to note wet/dry weather and hot or not days (temperature)\n",
    "weather['dry'] = np.where(weather['rain'] > 0.0, 1, 0)\n",
    "weather['warm'] = np.where(weather['temp'] > 18.0, 1, 0)\n",
    "weather.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge weather with bikes data\n",
    "merged_data = pd.merge(data, weather, on = 'date_for_merge', how = 'left')\n",
    "\n",
    "# identify bike arrivals and bike departures\n",
    "merged_data['BIKE_ARR_DEP'] = merged_data.groupby('STATION ID')['AVAILABLE BIKE STANDS'].diff(-1)\n",
    "merged_data['BIKE_ARR'] = np.where(merged_data['BIKE_ARR_DEP'] > 0, merged_data['BIKE_ARR_DEP'], 0)\n",
    "merged_data['BIKE_DEP'] = np.where(merged_data['BIKE_ARR_DEP'] < 0, merged_data['BIKE_ARR_DEP'], 0)\n",
    "merged_data['ACTIVITY_TYPE'] = np.where(abs(merged_data['BIKE_ARR_DEP']) >= 10, \"REBALANCING\", \"RENTAL\")\n",
    "merged_data['IMBALANCED'] = np.where(merged_data['OCCUPANCY_PCT'] < .1, 1, \n",
    "                                   np.where(merged_data['OCCUPANCY_PCT'] > .9, 1,0 ))\n",
    "\n",
    "# Identify days with rebalancing\n",
    "merged_data['REBALANCING'] = np.where(merged_data['ACTIVITY_TYPE'] == 'REBALANCING', 1,0)\n",
    "merged_data['JOIN_ON'] = merged_data['STATION ID'].apply(str)  + (merged_data['DATE']).apply(str) \n",
    "join_table= merged_data.groupby(['JOIN_ON'])['REBALANCING'].sum()\n",
    "merged_data = merged_data.drop(['REBALANCING'], axis = 1)\n",
    "join_table = join_table.to_frame()\n",
    "join_table =join_table.reset_index()\n",
    "merged_data = pd.merge(merged_data, join_table, on = 'JOIN_ON', how = 'left')\n",
    "merged_data = merged_data.drop(['JOIN_ON'], axis = 1)\n",
    "\n",
    "merged_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group data into clusters\n",
    "clustering_df = merged_data[['STATION ID', 'NAME', 'LATITUDE', 'LONGITUDE', 'DAY_TYPE', 'TIME_TYPE', 'OCCUPANCY_PCT','CLUSTER_GROUP']]\n",
    "clustering_df = clustering_df.groupby(['STATION ID', 'NAME', 'LATITUDE', 'LONGITUDE', 'CLUSTER_GROUP'],as_index=False)['OCCUPANCY_PCT'].mean()\n",
    "clustering_df  = clustering_df.set_index('STATION ID')\n",
    "\n",
    "#pivot dataframe for clustering\n",
    "clustering_df = clustering_df.pivot_table(index= ['NAME', 'STATION ID','LATITUDE', 'LONGITUDE'] , columns=['CLUSTER_GROUP'], values='OCCUPANCY_PCT')\n",
    "clustering_df  = clustering_df.reset_index()\n",
    "clustering_df  = clustering_df .set_index('NAME')\n",
    "clustering_df = clustering_df.dropna()\n",
    "\n",
    "clustering_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "K = range(1,10)\n",
    "X = np.array(clustering_df.drop(['STATION ID', 'LATITUDE', 'LONGITUDE'], 1).astype(float))\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k)\n",
    "    kmeanModel.fit(X)\n",
    "    distortions.append(kmeanModel.inertia_)\n",
    "    \n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering algo\n",
    "X = np.array(clustering_df.drop(['STATION ID', 'LATITUDE', 'LONGITUDE'], 1).astype(float))\n",
    "KM = KMeans(n_clusters=5) \n",
    "KM.fit(X)\n",
    "clusters = KM.predict(X)\n",
    "\n",
    "locations = clustering_df\n",
    "locations['Cluster'] = clusters\n",
    "locations = locations.reset_index()\n",
    "locations.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colordict = {0: 'blue', 1: 'red', 2: 'orange', 3: 'green', 4: 'purple'}\n",
    "dublin_map = folium.Map([53.345, -6.2650], zoom_start=13.5)\n",
    "for LATITUDE, LONGITUDE, Cluster in zip(locations['LATITUDE'],locations['LONGITUDE'], locations['Cluster']):\n",
    "    folium.CircleMarker(\n",
    "        [LATITUDE, LONGITUDE],\n",
    "        color = 'b',\n",
    "        radius = 8,\n",
    "        fill_color=colordict[Cluster],\n",
    "        fill=True,\n",
    "        fill_opacity=0.9\n",
    "        ).add_to(dublin_map)\n",
    "dublin_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge clusters back into main dataset\n",
    "\n",
    "merged_with_clusters = merged_data\n",
    "cluster_output = locations[['STATION ID', 'Cluster']]\n",
    "cluster_output.drop_duplicates(keep = 'first', inplace = True)\n",
    "del merged_data\n",
    "merged_with_clusters = pd.merge (merged_with_clusters, cluster_output, on = 'STATION ID', how = 'left')\n",
    "merged_with_clusters['BIKE_ARR_DEP_ABS'] = abs(merged_with_clusters['BIKE_ARR_DEP'])\n",
    "merged_with_clusters.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linechart_data = merged_with_clusters[['DAY_TYPE', 'Cluster', 'HOUR', 'OCCUPANCY_PCT']]\n",
    "linechart_data['Cluster'] = np.where(linechart_data['Cluster'] == 0, 'City Centre',\n",
    "                                    np.where(linechart_data['Cluster'] == 1, 'Grangegorman',\n",
    "                                            np.where(linechart_data['Cluster'] == 2, 'Transport Hubs',\n",
    "                                                    np.where(linechart_data['Cluster'] == 3, 'Docklands & South City', 'Outer Suburbs'))))\n",
    "\n",
    "#Weekday\n",
    "linechart_data_weekday = linechart_data[linechart_data['DAY_TYPE'] == 'Weekday']\n",
    "linechart_data_weekday = linechart_data_weekday.groupby(['HOUR', 'Cluster'])['OCCUPANCY_PCT'].mean()\n",
    "linechart_data_weekday  = linechart_data_weekday.reset_index()\n",
    "y1 = linechart_data_weekday['OCCUPANCY_PCT'].values\n",
    "x1 = linechart_data_weekday['HOUR'].values\n",
    "labels1 = linechart_data_weekday['Cluster'].values\n",
    "colours1 = linechart_data_weekday['Cluster'].values\n",
    "df1 = pd.DataFrame(dict(x=x1, y=y1, label=labels1))\n",
    "groups1 = df1.groupby('label')\n",
    "\n",
    "#Saturday\n",
    "linechart_data_saturday = linechart_data[linechart_data['DAY_TYPE'] == 'Saturday']\n",
    "linechart_data_saturday = linechart_data_saturday.groupby(['HOUR', 'Cluster'])['OCCUPANCY_PCT'].mean()\n",
    "linechart_data_saturday  = linechart_data_saturday.reset_index()\n",
    "y2 = linechart_data_saturday['OCCUPANCY_PCT'].values\n",
    "x2 = linechart_data_saturday['HOUR'].values\n",
    "labels2 = linechart_data_saturday['Cluster'].values\n",
    "colours2 = linechart_data_saturday['Cluster'].values\n",
    "df2 = pd.DataFrame(dict(x=x2, y=y2, label=labels2))\n",
    "groups2 = df2.groupby('label')\n",
    "\n",
    "#Sunday\n",
    "linechart_data_sunday = linechart_data[linechart_data['DAY_TYPE'] == 'Sunday']\n",
    "linechart_data_sunday = linechart_data_sunday.groupby(['HOUR', 'Cluster'])['OCCUPANCY_PCT'].mean()\n",
    "linechart_data_sunday  = linechart_data_sunday.reset_index()\n",
    "y3 = linechart_data_sunday['OCCUPANCY_PCT'].values\n",
    "x3 = linechart_data_sunday['HOUR'].values\n",
    "labels3 = linechart_data_sunday['Cluster'].values\n",
    "colours3 = linechart_data_sunday['Cluster'].values\n",
    "df3 = pd.DataFrame(dict(x=x3, y=y3, label=labels3))\n",
    "groups3 = df3.groupby('label')\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 22\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for name, group in groups1:\n",
    "    axs[0].plot(group.x, group.y, label=name)\n",
    "    axs[0].set_title('Weekday')\n",
    "    axs[0].set_xlabel('Hour')\n",
    "    axs[0].set_ylabel('Occupancy %')\n",
    "    #fig.suptitle('This is a somewhat long figure title', fontsize=16)\n",
    "\n",
    "for name, group in groups2:\n",
    "    axs[1].plot(group.x, group.y, label=name)\n",
    "    axs[1].set_title('Saturday')\n",
    "    axs[1].set_xlabel('Hour')\n",
    "    axs[1].set_ylabel('Occupancy %')\n",
    "    \n",
    "\n",
    "for name, group in groups3:\n",
    "    axs[2].plot(group.x, group.y, label=name)\n",
    "    axs[2].set_title('Sunday')\n",
    "    axs[2].set_xlabel('Hour')\n",
    "    axs[2].set_ylabel('Occupancy %')\n",
    "    axs[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact of Stations\n",
    "join_table= merged_with_clusters.groupby(['STATION ID','NAME', 'DATE']).agg(rain=('rain', 'sum'), TOTAL_CHANGES=('BIKE_ARR_DEP_ABS', 'sum'))\n",
    "join_table =join_table.reset_index()\n",
    "join_table['WET/DRY DAY'] = np.where(join_table['rain'] > 3, \"Wet\", \"Dry\")\n",
    "join_table = join_table.drop(['rain'], axis = 1)\n",
    "join_table =join_table.reset_index()\n",
    "merged_with_clusters_wetdry = pd.merge(merged_with_clusters, join_table, on = ['STATION ID', 'NAME', 'DATE'], how = 'left')\n",
    "\n",
    "wetday_df= merged_with_clusters_wetdry.groupby(['STATION ID', 'NAME', 'WET/DRY DAY']).agg(AVG_CHANGES=('TOTAL_CHANGES', 'mean'))\n",
    "wetday_df =wetday_df.reset_index()\n",
    "difference_df = wetday_df.pivot(index=['NAME'], columns='WET/DRY DAY', values='AVG_CHANGES').reset_index()\n",
    "difference_df['Change'] = difference_df['Dry'] - difference_df['Wet']\n",
    "difference_df.sort_values(by = 'Change', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y = wetday_df['AVG_CHANGES'].values\n",
    "x = wetday_df['STATION ID'].values\n",
    "labels = wetday_df['WET/DRY DAY'].values\n",
    "colours = wetday_df['WET/DRY DAY'].values\n",
    "df = pd.DataFrame(dict(x=x, y=y, label=labels))\n",
    "groups = df.groupby('label')\n",
    "\n",
    "SMALL_SIZE = 20\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 22\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 10))\n",
    "#ax.set_color_cycle(colors)\n",
    "ax.margins(0.05)\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y,  marker='o',  linestyle='', ms=15, label=name)\n",
    "ax.legend(numpoints=1, loc='upper left')\n",
    "plt.xlabel(\"Station ID\")\n",
    "plt.ylabel(\"Avg Rentals/Day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Occupancy Percentage Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_classifier_data = merged_with_clusters[merged_with_clusters['REBALANCING'] < 1] #exclude days where rebalancing took place\n",
    "ml_classifier_data = ml_classifier_data[['STATION ID', 'OCCUPANCY_PCT' , 'dry', 'warm', 'DAY_NUMBER', 'HOUR', 'MONTH']]\n",
    "\n",
    "\n",
    "def bin_occupancy(x):\n",
    "    if x < 0.1:\n",
    "        return 0\n",
    "    elif x < 0.1:\n",
    "        return 0.1\n",
    "    elif x < 0.2:\n",
    "        return 0.1\n",
    "    elif x < 0.3:\n",
    "        return 0.1\n",
    "    elif x < 0.4:\n",
    "        return 0.1\n",
    "    elif x < 0.5:\n",
    "        return 0.1\n",
    "    elif x < 0.6:\n",
    "        return 0.1\n",
    "    elif x < 0.7:\n",
    "        return 0.1\n",
    "    elif x < 0.8:\n",
    "        return 0.1\n",
    "    else:\n",
    "        return 0.2\n",
    "\n",
    "ml_classifier_data[\"OCC_GROUP\"] = ml_classifier_data['OCCUPANCY_PCT'].apply(bin_occupancy)\n",
    "ml_classifier_data[\"OCC_GROUP\"] = ml_classifier_data[\"OCC_GROUP\"] * 10\n",
    "ml_classifier_data[\"OCC_GROUP\"] = ml_classifier_data[\"OCC_GROUP\"].astype(int)\n",
    "ml_classifier_data.dropna(inplace = True)\n",
    "msk = np.random.rand(len(ml_classifier_data)) < 0.8\n",
    "train = ml_classifier_data[msk]\n",
    "test = ml_classifier_data[~msk]\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "X_train = train.drop(['OCCUPANCY_PCT', \"OCC_GROUP\"], axis = 1)\n",
    "X_test = test.drop(['OCCUPANCY_PCT', \"OCC_GROUP\"], axis = 1)\n",
    "Y_train = train[[\"OCC_GROUP\"]] \n",
    "Y_test = test[[\"OCC_GROUP\"]]\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "#pd.crosstab(y_true, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "print(sklearn.metrics.classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show feature importances \n",
    "\n",
    "feature_imp = pd.Series(clf.feature_importances_,index=['STATION ID','DRY', 'WARM', 'DAY_NUMBER', 'HOUR', 'MONTH']).sort_values(ascending=False)\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
